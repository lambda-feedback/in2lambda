{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# process description  \n",
    "\n",
    "the program takes in a pdf  \n",
    "mathpix is used to scan the pdf and turning it into markdown  \n",
    "markdown then processed to get the images  \n",
    "\n",
    "llm is used to extract the questions and solutions in **ONE** go.  \n",
    "the final JSON is made using the in2lambda api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import pypandoc\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from in2lambda.api.module import Module\n",
    "from in2lambda.api.question import Question\n",
    "from in2lambda.api.part import Part\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables from .env file.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# scanning/processing the initial pdf into markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATHPIX_API_KEY = os.getenv(\"MATHPIX_API_KEY\")\n",
    "MATHPIX_APP_ID = os.getenv(\"MATHPIX_APP_ID\")\n",
    "\n",
    "def pdf_to_markdown(source_path: str, result_path: str):\n",
    "    ''' \n",
    "    converts the pdf at `source_path` to a markdown file at `result_path` using Mathpix API.\n",
    "    '''\n",
    "    # Upload PDF to Mathpix and returns a Markdown file with the content.\n",
    "    with open(source_path, \"rb\") as file:\n",
    "        r = requests.post(\n",
    "            \"https://api.mathpix.com/v3/pdf\",   \n",
    "            headers={\n",
    "                \"app_id\": MATHPIX_APP_ID,\n",
    "                \"app_key\": MATHPIX_API_KEY,\n",
    "            },\n",
    "            files={\"file\": file},\n",
    "        )\n",
    "        pdf_id = r.json()[\"pdf_id\"]\n",
    "        print(\"PDF ID:\", pdf_id)\n",
    "        print(\"Response:\", r.json())\n",
    "\n",
    "        # url of where the location of the processed PDF will be\n",
    "        url = f\"https://api.mathpix.com/v3/pdf/{pdf_id}.md\"\n",
    "        headers = {\n",
    "            \"app_id\": MATHPIX_APP_ID,\n",
    "            \"app_key\": MATHPIX_API_KEY,\n",
    "        }\n",
    "\n",
    "        max_retries = 10\n",
    "        retry_delay = 5  # seconds\n",
    "        for attempt in range(max_retries):\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                # Save the result if the request is successful\n",
    "                with open(result_path, \"w\") as f:\n",
    "                    f.write(response.text)\n",
    "                print(\"Downloaded MD successfully.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Attempt {attempt + 1}/{max_retries}: Processing not complete. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "        else:\n",
    "            print(\"Failed to retrieve processed PDF after multiple attempts:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# setting up the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the output folder and media folder.\n",
    "folder_path = \"conversion_content\"\n",
    "input_path = f\"{folder_path}/input\"\n",
    "output_path = f\"{folder_path}/mathpix_to_llm_with_lines_to_api\"\n",
    "media_path = f\"{output_path}/media\"\n",
    "\n",
    "# Create output and media directories if they do not exist.\n",
    "Path(media_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# location of the source pdf file and the result markdown file.\n",
    "files = [f for f in os.listdir(input_path) if f != '.gitkeep']\n",
    "source_path = f\"{input_path}/{files[0]}\" # the first file in the input folder\n",
    "result_path = f\"{output_path}/example.md\"\n",
    "\n",
    "\n",
    "\n",
    "# Only activate mathpix if the markdown has not been created yet.\n",
    "# This avoids unnecessary reprocessing of the same PDF.\n",
    "if not Path(result_path).exists():\n",
    "    if Path(source_path).exists():\n",
    "        extension = Path(source_path).suffix.lower() # obtains the file extension\n",
    "        if extension == \".pdf\":\n",
    "            pdf_to_markdown(source_path, result_path)\n",
    "        else:\n",
    "            pypandoc.convert_file(source_path, 'md', outputfile=result_path)\n",
    "    else:\n",
    "        print(f\"Error: Source PDF file not found at {source_path}\")\n",
    "        exit(1)\n",
    "\n",
    "# Read the markdown content from the result file.\n",
    "try:\n",
    "    with open(result_path, \"r\") as f:\n",
    "        md_content = f.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Markdown file not found at {result_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Print out a summary.\n",
    "print(\"Markdown text: \")\n",
    "print(f\"  {result_path}: {len(md_content)} characters\")\n",
    "print(\"Markdown text: \")\n",
    "print(f\"  {result_path}: {md_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# downlaoding extracted images from Mathpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the figures from the paper and answers.\n",
    "def extract_figures_from_text(text): #, ans=False):\n",
    "    \"\"\"\n",
    "    Extracts figures from the text using regex.\n",
    "    Finds figure references and their descriptions.\n",
    "    \"\"\"\n",
    "    figures = {}\n",
    "    # Regex to match figure references and their descriptions\n",
    "    # Matches ![alt text](url) format for images\n",
    "    pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    print(f\"Matches found: {matches}\")\n",
    "    \n",
    "    for match in matches:\n",
    "        url = match\n",
    "        url = url.strip()\n",
    "        \n",
    "        if url.startswith(\"http\"):\n",
    "            # Download the image and save it to a file\n",
    "            image = Image.open(requests.get(url, stream=True).raw)\n",
    "            # Create a figure name based on the URL\n",
    "            fig_name = os.path.basename(url)\n",
    "            figures[fig_name] = {\n",
    "                \"image\": image,\n",
    "                \"url\": url,\n",
    "                \"local_path\": \"\",\n",
    "                # \"answerFile\": ans\n",
    "            }\n",
    "    return figures\n",
    "\n",
    "# a dictionary storing information on the figures\n",
    "figures = extract_figures_from_text(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# saving the images locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figures_to_path(figures):\n",
    "    for idx, (fig_name, fig_info) in enumerate(figures.items()):\n",
    "        print(f\"URL='{fig_info['url']}'\")\n",
    "\n",
    "        # Extract file extension and create a clean filename\n",
    "        # Mathpix leaves image urls like `image.png?width=800&height=600`\n",
    "        # We only want the base name without query parameters.\n",
    "        if \"?\" in fig_name:\n",
    "            end_location = fig_name.index(\"?\")\n",
    "            image_name = f\"{idx}_{fig_name[:end_location]}\"\n",
    "        else:\n",
    "            image_name = f\"{idx}_{fig_name}\"\n",
    "        \n",
    "        fig_info[\"local_path\"] = image_name\n",
    "        try:\n",
    "            # Saves the image to the media path\n",
    "            fig_info[\"image\"].save(f\"{media_path}/{fig_info['local_path']}\")\n",
    "            print(f\"Saved image: {fig_info['local_path']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image {image_name}: {e}\")\n",
    "\n",
    "save_figures_to_path(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# replacing url for images with local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_figures_in_markdown(md_content, figures) -> str:\n",
    "    #replace the image URLs in the markdown content with local paths\n",
    "    # add pictureTag for Lambda Feedback to recognise it as a picture\n",
    "    md_content = md_content.replace(\"![]\", \"![pictureTag]\")\n",
    "    for fig_name, fig_info in figures.items():\n",
    "        md_content = md_content.replace(fig_info[\"url\"], fig_info[\"local_path\"])\n",
    "        print(f\"Replaced {fig_info['url']} with {fig_info['local_path']} in markdown content.\")\n",
    "    # Save the modified markdown content to a file\n",
    "    try:\n",
    "        with open(f\"{output_path}/example.md\", \"w\") as f:\n",
    "            f.write(md_content)\n",
    "        print(\"Modified markdown saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving modified markdown: {e}\")\n",
    "    \n",
    "    return md_content\n",
    "\n",
    "md_content = replace_figures_in_markdown(md_content, figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Initialising llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM via LangChain.\n",
    "\n",
    "# Uses gpt-4.1-nano:\n",
    "#    - a faster model\n",
    "#    - less intelligent\n",
    "\n",
    "llm_nano = ChatOpenAI(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        )\n",
    "\n",
    "# Uses gpt-5-mini:\n",
    "#    - more intelligent\n",
    "llm_mini = ChatOpenAI(\n",
    "            model=\"gpt-5-mini\",\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            reasoning_effort=\"minimal\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Spelling and structure check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_task_correct_mistakes = \"\"\"\n",
    "The input is a markdown file that is converted from a pdf using Mathpix API.\n",
    "The pdf contains questions and may contain the solutions too.\n",
    "As the original pdf may contain hand written text, the markdown file may contain mistakes in spelling, grammar and structure.\n",
    "\n",
    "Important things to remember:\n",
    "    1. Leave all Math commands and LaTeX formatting the same. As they are completely valid. Do not change the LaTeX formatting and expressions.\n",
    "    2. Only ever use LaTeX math delimiters for math expressions. I.e. use `$...$` for inline math, and `$$...$$` for display math.\n",
    "    3. Leave references to images and figures the same. I.e. do not change the image links or alt text.\n",
    "\n",
    "Your task is to:\n",
    "    1. Correct any spelling mistakes in the markdown file.\n",
    "    2. Correct any grammar mistakes in the markdown file.\n",
    "    3. Correct any layout mistakes in the markdown file, such that it follows the styles of the entire markdown file.\n",
    "    4. Do not change the content of the markdown file, only correct the mistakes.\n",
    "Output only a valid markdown file with the corrections applied, if any. Do not add any additional text or comments.\n",
    "\"\"\"\n",
    "\n",
    "def correct_mistakes_in_markdown(md_content: str) -> str:\n",
    "    correct_mistakes_prompt = f\"\"\"\n",
    "        {llm_task_correct_mistakes}\n",
    "\n",
    "        ```input\n",
    "        {md_content}\n",
    "        ```\n",
    "\n",
    "        Return the markdown now.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm_nano.invoke(correct_mistakes_prompt)\n",
    "    print(\"Corrected markdown content:\")\n",
    "    print(response.content.strip())\n",
    "\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Transform into markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate representation of the markdown\n",
    "class Markdown():\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "\n",
    "class DisplayMath(Markdown):\n",
    "    content = \"\"\n",
    "    \n",
    "    def __init__(self, content):\n",
    "        super().__init__(content)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"$$\\n{self.content}\\n$$\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DisplayMath({self.content!r})\"\n",
    "\n",
    "class RegularText(Markdown):\n",
    "    def __init__(self, content):\n",
    "        super().__init__(content)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.content\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"RegularText({self.content!r})\"\n",
    "\n",
    "\n",
    "def markdown_to_classes(markdown: str) -> list[Markdown]:\n",
    "    lines = markdown.split(\"\\n\")\n",
    "    ret = []\n",
    "    math_buffer = []\n",
    "    displayMath = False\n",
    "    for line in lines:\n",
    "        if line == \"$$\":\n",
    "            displayMath = not displayMath\n",
    "            if not displayMath:\n",
    "                ret.append(DisplayMath(\"\\n\".join(math_buffer)))\n",
    "                math_buffer = []\n",
    "        else:\n",
    "            if displayMath:\n",
    "                math_buffer.append(line)\n",
    "            else:\n",
    "                ret.append(RegularText(line))\n",
    "    return ret\n",
    "\n",
    "def classes_to_markdown(classes: list[Markdown]) -> str:\n",
    "    lines = []\n",
    "    for c in classes:\n",
    "        lines.append(str(c))\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Extract Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define initial question model\n",
    "class QuestionModelLines(BaseModel):\n",
    "    # full question and full solution\n",
    "    question_content_start: int = Field(..., description=\"Line number the question starts on.\")\n",
    "    question_content_end: int = Field(..., description=\"Line number the question ends on.\")\n",
    "    solution_content_start: int = Field(..., description=\"Line number the solution starts on.\")\n",
    "    solution_content_end: int = Field(..., description=\"Line number the solution ends on.\")\n",
    "\n",
    "class AllQuestionsModelLines(BaseModel):\n",
    "    name: str = Field(..., description=\"Title of the set\")\n",
    "    year: str = Field(..., description=\"Year of the set\")\n",
    "    questions: list[QuestionModelLines] = Field(..., description=\"A list of questions.\")\n",
    "\n",
    "llm_task_seperate_questions = \"\"\"\n",
    "    Your task is to extract the line numbers for the start and end of all the question and solution from the markdown file, then format it as a JSON object.\n",
    "    Note that the questions and solutions may not be around the same area in the markdown file.\n",
    "    These line numbers will be used later to extract the content of the questions and solutions procedurally.\n",
    "    \n",
    "    1.  **Content Extraction:**\n",
    "        -   Your may choose a suitable name for the set of questions.\n",
    "        -   Identify the `year` of the questions, otherwise use \"0\".\n",
    "        -   Begin by identifying all the distinct individual questions in the markdown file, which are likely explicitly enumerated, and for each question:\n",
    "            -   Identify the start and end line numbers of the full question content, and place them in `question_content_start` and `question_content_end`.\n",
    "            -   Identify the start and end line numbers of the full relevant solution content, and place them in `solution_content_start` and `solution_content_end`.\n",
    "            -   Be careful to ensure that everything related to the question and solution is included, including any math delimiters($, $$) and LaTeX formatting.\n",
    "            -   Do not forget to include any images or figures that are part of the question or solution.\n",
    "    \n",
    "    2.  **Output Format:**\n",
    "        -   You MUST output ONLY a single, raw, valid JSON string that matches the provided schema.\n",
    "        -   Do NOT include any explanations, comments, or markdown code blocks (like ```json).\n",
    "    \"\"\"\n",
    "\n",
    "example_seperate_questions = \"\"\"\n",
    "    Example input:\n",
    "    [(0, \"Q1: Give a fruit begining with these letters:\"),\n",
    "    (1, \"a) a\"),\n",
    "    (2, \"b) b\"),\n",
    "    (3, \"c) c\"),\n",
    "    (4, \"Q2: What is the capital of France?\"),\n",
    "    (5, \"Q3: What is the colour of the sky?\"),\n",
    "    (6, \"A1:\"),\n",
    "    (7, \"a) = apple\"),\n",
    "    (8, \"b) = banana\"),\n",
    "    (9, \"c) = cherry\"),\n",
    "    (10, \"A2: Paris is the capital of France.\"),\n",
    "    (11, \"A3: The sky is blue.\")\n",
    "    ]\n",
    "\n",
    "    example output:\n",
    "    {\n",
    "        \"name\": \"Suitable Name\",\n",
    "        \"year\": \"0\",\n",
    "        \"questions\": [\n",
    "            {\n",
    "                \"question_content_start\": 0,\n",
    "                \"question_content_end\": 3,\n",
    "                \"solution_content_start\": 5,\n",
    "                \"solution_content_end\": 8\n",
    "            },\n",
    "            {\n",
    "                \"question_content_start\": 4,\n",
    "                \"question_content_end\": 4,\n",
    "                \"solution_content_start\": 9,\n",
    "                \"solution_content_end\": 9\n",
    "            },\n",
    "            {\n",
    "                \"question_content_start\": 5,\n",
    "                \"question_content_end\": 5,\n",
    "                \"solution_content_start\": 10,\n",
    "                \"solution_content_end\": 10\n",
    "            },\n",
    "            {\n",
    "                \"question_content_start\": 6,\n",
    "                \"question_content_end\": 6,\n",
    "                \"solution_content_start\": 11,\n",
    "                \"solution_content_end\": 11\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "# Prompt for the LLM to extract questions.\n",
    "def seperate_questions_prompt(parser: PydanticOutputParser[AllQuestionsModelLines], doc_page_content: list[str]) -> str: #, previous_repsonse: str = \"\", improvements: list[str] = \"\") -> str:\n",
    "\n",
    "    feedback = \"\"\n",
    "    # if previous_repsonse:\n",
    "    #     feedback = f\"\"\"\n",
    "        \n",
    "    #         Previous output:\n",
    "    #         {previous_repsonse}\n",
    "\n",
    "    #         Improvements:\n",
    "    #         {improvements}\n",
    "\n",
    "    #     \"\"\"\n",
    "\n",
    "    return f\"\"\"\n",
    "        Your task is to extract a JSON with the following structure exactly, ready to be parsed by a pydantic model:\n",
    "        {parser.get_format_instructions()}\n",
    "\n",
    "        {llm_task_seperate_questions}\n",
    "\n",
    "        {example_seperate_questions}\n",
    "\n",
    "        Input markdown:\n",
    "        ```\n",
    "        {list(enumerate(doc_page_content))}\n",
    "        ```\n",
    "        {feedback}\n",
    "        Return the JSON now.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# extracting images from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extracts image URLs from the markdown text.\n",
    "    Returns a list of image URLs.\n",
    "    \"\"\"\n",
    "    pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# extracting questions form the problem sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionModel(BaseModel):\n",
    "    # full question and full solution\n",
    "    question_content: str = Field(..., description=\"The content of the question.\")\n",
    "    solution_content: str = Field(..., description=\"The content of the solution.\")\n",
    "    images: list[str] = Field(..., description=\"A list of image URLs associated with the question.\")\n",
    "\n",
    "class AllQuestionsModel(BaseModel):\n",
    "    name: str = Field(..., description=\"Title of the set\")\n",
    "    year: str = Field(..., description=\"Year of the set\")\n",
    "    questions: list[QuestionModel] = Field(..., description=\"A list of questions.\")\n",
    "\n",
    "\n",
    "def extract_questions(allQuestionsModel: AllQuestionsModelLines, doc_page_content: list[str]) -> AllQuestionsModel:\n",
    "    \"\"\"\n",
    "    Extracts questions from the AllQuestions model and returns a list of Question objects.\n",
    "    \"\"\"\n",
    "    print(\"Extracting questions from the AllQuestions model...\")\n",
    "\n",
    "    name = allQuestionsModel.name\n",
    "    year = allQuestionsModel.year\n",
    "    questions = []\n",
    "\n",
    "    for question in allQuestionsModel.questions:\n",
    "        question_content = \"\\n\".join(doc_page_content[question.question_content_start:question.question_content_end+1])\n",
    "        solution_content = \"\\n\".join(doc_page_content[question.solution_content_start:question.solution_content_end+1])\n",
    "        #important, image will be wrong if two identical images are used, although this should not be possible.\n",
    "        images = list(set(extract_images(question_content) + extract_images(solution_content)))\n",
    "\n",
    "        questions.append(\n",
    "            QuestionModel(\n",
    "                question_content=question_content,\n",
    "                solution_content=solution_content,\n",
    "                images=images\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    allQuestions = AllQuestionsModel(\n",
    "        name=name,\n",
    "        year=year,\n",
    "        questions=questions\n",
    "    )\n",
    "    \n",
    "    print(f\"Extracted {len(questions)} questions from the AllQuestions model.\")\n",
    "    return allQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionSeperationEvaluation(BaseModel):\n",
    "    well_separated: bool = Field(..., description=\"Whether the question was separated well.\")\n",
    "    improvements: list[str] = Field(..., description=\"List of improvements to be made to the question separation.\")\n",
    "\n",
    "def evaluate_questions_separation(parsed_output: AllQuestionsModel, markdown: list[str]) -> list[QuestionSeperationEvaluation]:\n",
    "    print(\"begin evaluation of llm output for question separation...\")\n",
    "\n",
    "    def evaluate_single_question_separation(question: QuestionModel) -> QuestionSeperationEvaluation:\n",
    "\n",
    "        parser = PydanticOutputParser(pydantic_object=QuestionSeperationEvaluation)\n",
    "        \n",
    "        llm_task_evaluate_question_separation = f\"\"\"\n",
    "        Your task is to evaluate the question separation of the following question.\n",
    "        After evaluating the question separation, return a JSON object with the following structure:\n",
    "        {parser.get_format_instructions()}\n",
    "\n",
    "        Earlier, an llm was used to separate a markdown file into questions and its relavant solution by returning the lines where the question and solution start and end.\n",
    "        This is to ensure that the math delimiters and laTeX formatting is preserved, since the original markdown has perfect formatting and structure.\n",
    "        However, as with any LLM, it may not have returned the best lines for this particular question.\n",
    "        Evaluate this one singular full question, which has been procedurally extracted from the markdown file using the lines given by the llm.\n",
    "        Using the full markdown, check if the question was extracted correctly (note that the question and its solution may not be in the same area), in particular, check that:\n",
    "            -  There is only 1 full question per `question_content`.\n",
    "            -  The full question content from the markdown is included, which may contain its sub-questions and parts, which is fine as it will be separated later.\n",
    "            -  The full solution content from the markdown is included, which should include the full solution for the question and its parts.\n",
    "            -  The question and solution Text should have its math delimiters($, $$) and LaTeX formatting preserved and well closed.\n",
    "            -  Ignore all typos and grammar mistakes, since they are not relevant to the question separation.\n",
    "            -  only comment on things that can be improved.\n",
    "        Be Very precise with what you believe is wrong, if any.\n",
    "        If you believe the question was separated fairly well, set `well_separated` to true and leave `improvements` empty.\n",
    "        If you believe the question was not separated correctly, set `well_separated` to false and provide a list of precise, improvements to be made.\n",
    "\n",
    "        example input #1 valid questions:\n",
    "        {{\n",
    "            \"question_content\": \"1. Give a fruit beginning with these letters: a) A, b) B, c) C\",\n",
    "            \"solution_content\": \"1. a) = apple, b) = banana, c) = cherry\",\n",
    "            \"images\": []\n",
    "        }}\n",
    "        example output #2 well separated response:\n",
    "        {{\n",
    "            \"well_separated\": True,\n",
    "            \"improvements\": []\n",
    "        }}\n",
    "\n",
    "        example input #2 invalid questions:\n",
    "        {{\n",
    "            \"question_content\": \"3. Give the capital of France? \\n 4. What is the colour of the sky?\",\n",
    "            \"solution_content\": \"3. Paris, 4. Blue\",\n",
    "            \"images\": []\n",
    "        }}\n",
    "        example output #2 not well separated response:\n",
    "        {{\n",
    "            \"well_separated\": False,\n",
    "            \"improvements\": [\n",
    "                \"Two full questions were found in the question content.\",\n",
    "                \"Two full solutions were found in the solution content.\",\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        example input #3 invalid questions:\n",
    "        {{\n",
    "            \"question_content\": \"Q1: solve for x: 2x + 3 = 7\",\n",
    "            \"solution_content\": \"\\\\begin{{aligned}} 2x + 3 &= 7 \\\\\\\\ 2x &= 4 \\\\\\\\ x &= 2 \\end{{aligned}}\",\n",
    "            \"images\": []\n",
    "        }} \n",
    "        example output #3 not well separated response:\n",
    "        {{\n",
    "            \"well_separated\": False,\n",
    "            \"improvements\": [\n",
    "                \"Missing opening and closing math delimiters around the LaTeX solution display math.\",\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        full markdown:\n",
    "        {markdown}\n",
    "\n",
    "        extracted question:\n",
    "        {question}\n",
    "\n",
    "        return the JSON now.\n",
    "        \"\"\"\n",
    "\n",
    "        for attempt_idx in range(3):\n",
    "            try:\n",
    "                response = llm_nano.invoke(llm_task_evaluate_question_separation)\n",
    "                parsed_response = parser.parse(response.content)\n",
    "                return parsed_response\n",
    "            except:\n",
    "                print(f\"Evaluation parse error on attempt {attempt_idx + 1}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Failed to evaluate question separation after 3 attempts.\")\n",
    "\n",
    "    # Use ThreadPoolExecutor to evaluate each question in parallel.\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        questions_in_parts = list(executor.map(evaluate_single_question_separation, parsed_output.questions))\n",
    "\n",
    "    print(\"Evaluated all questions for separation.\")\n",
    "    return questions_in_parts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extract_questions_lines(markdown: list[str]) -> dict:\n",
    "    print(\"Begining to seperate the questions from the markdown content...\")\n",
    "    \n",
    "    # Initialise the parser for the output.\n",
    "    parser = PydanticOutputParser(pydantic_object=AllQuestionsModelLines)\n",
    "\n",
    "    previous_response = \"\"\n",
    "    improvements = []\n",
    "\n",
    "    for attempt_idx in range(3):\n",
    "        try:\n",
    "            response = llm_mini.invoke(seperate_questions_prompt(parser, markdown)) #, previous_response, improvements))\n",
    "            parsed_response = parser.parse(response.content)\n",
    "            questions_dict = extract_questions(parsed_response, markdown)\n",
    "            print(questions_dict.model_dump_json())\n",
    "\n",
    "            # evaluation = evaluate_questions_separation(parsed_output=questions_dict, markdown=markdown)\n",
    "            # if all(e.well_separated for e in evaluation):\n",
    "            if True:\n",
    "                print(\"Question separation was successful.\")\n",
    "                return questions_dict.model_dump()\n",
    "            else:\n",
    "                previous_response = parsed_response.model_dump_json()\n",
    "                improvements = [f\"question {i + 1} improvements:{evaluation[i].improvements}\" for i in range(len(evaluation)) if not evaluation[i].well_separated]\n",
    "                print(f\"Evaluation failed. trying again... {improvements}\")\n",
    "        except:\n",
    "            print(f\"Parse error on attempt {attempt_idx + 1}\")\n",
    "    else:\n",
    "        raise Exception(\"Failed to extract questions after 3 attempts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Extract question parts and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the tutorial output.\n",
    "class Set_Question_Part_Lines(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a part of a question with its start and end lines.\n",
    "    \"\"\"\n",
    "    part_start: int = Field(..., description=\"The start line number of the part.\")\n",
    "    part_end: int = Field(..., description=\"The end line number of the part.\")\n",
    "    \n",
    "class Set_Question_Lines(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the question (only the text, no numbering)\")\n",
    "    content_start: int = Field(..., description=\"start of the content of the question (no exercise title, no subquestions)\")\n",
    "    content_end: int = Field(..., description=\"end of the content of the question (no exercise title, no subquestions)\")\n",
    "    parts: list[Set_Question_Part_Lines] = Field(..., description=\"List of parts within the question (only the text, no numbering)\")\n",
    "\n",
    "class Set_Question(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the question (only the text, no numbering)\")\n",
    "    content: str = Field(..., description=\"Content of the question (no exercise title, no subquestions)\")\n",
    "    parts: list[str] = Field(..., description=\"List of parts within the question (only the text, no numbering)\")\n",
    "    images: list[str] = Field(..., description=\"List of image URLs associated with the question (no alt text, only URLs)\")\n",
    "\n",
    "\n",
    "class Set_Solution_Part_Lines(BaseModel):\n",
    "    part_solution_start: int = Field(..., description=\"The start of the worked solution for the part (no numbering or counting)\")\n",
    "    part_solution_end: int = Field(..., description=\"The end of the worked solution for the part (no numbering or counting)\")\n",
    "\n",
    "class Set_Solution(BaseModel):\n",
    "    parts_solutions: list[str] = Field(..., description=\"List of worked solutions for the question (no numbering or counting)\")\n",
    "\n",
    "\n",
    "class Set_Question_With_Solution(Set_Question):\n",
    "    parts_solutions: list[str] = Field(..., description=\"The worked solution for the parts.\")\n",
    "\n",
    "    def __init__(self, question: Set_Question, solution: Set_Solution):\n",
    "        \"\"\"\n",
    "        Initialize the Set_Question_With_Solution with a question and its solution.\n",
    "        \n",
    "        Args: \n",
    "            question (Set_Question): The question object.\n",
    "            solution (Set_Solution): The solution object.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            **question.model_dump(),\n",
    "            parts_solutions=solution.parts_solutions,\n",
    "        )\n",
    "\n",
    "\n",
    "class Set_Lines(BaseModel):\n",
    "    name: str = Field(..., description=\"Title of the set\")\n",
    "    year: str = Field(..., description=\"Year of the set\")\n",
    "    questions: list[Set_Question_With_Solution] = Field(..., description=\"List of questions in the set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_set_question_lines_to_set_question(set_question_lines: Set_Question_Lines, question_content: list[str], images: list[str] = []) -> Set_Question:\n",
    "    \"\"\"\n",
    "    Convert Set_Question_Lines to Set_Question.\n",
    "    \"\"\"\n",
    "    return Set_Question(\n",
    "        title=set_question_lines.title,\n",
    "        content=\"\\n\".join(question_content[set_question_lines.content_start:set_question_lines.content_end + 1]),\n",
    "        parts=[\"\\n\".join(question_content[part.part_start:part.part_end + 1]) for part in set_question_lines.parts],\n",
    "        images=images\n",
    "    )\n",
    "\n",
    "def convert_set_solution_lines_to_set_solution(set_solution_lines: list[Set_Solution_Part_Lines], solution_content: list[str]) -> Set_Solution:\n",
    "    \"\"\"\n",
    "    Convert Set_Solution_Part_Lines to Set_Solution.\n",
    "    \"\"\"\n",
    "    return Set_Solution(\n",
    "        parts_solutions=[\n",
    "            \"\\n\".join(solution_content[part.part_solution_start:part.part_solution_end + 1])\n",
    "            for part in set_solution_lines\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_task_seperate_parts_question = r\"\"\"\n",
    "    1. **Content Extraction:**\n",
    "        -   You may choose the `title` for the question.\n",
    "        -   From the input `Full Question Content`, identify the start line and end line for the main introductory text (the stem), place them in `content_start` and `content_end`.\n",
    "        -   From the input `Full Question Content`, identify and separate all the `parts`(sub-questions), sub-questions should be able to be identified explicitly (e.g. using, \"(a)\", \"(b)\", \"i.\", \"ii.\"... etc.). For each identified sub-question:\n",
    "            -   Place the start line going into `part_start` and the end line going into `part_end`.\n",
    "            -   If the question has no sub-questions, leave `part_start` as 0 and `part_end` as -1.\n",
    "            -   You may use the `Full Solution Content` to help with identifying the parts.\n",
    "        -   Be careful to ensure that everything related to the question stem/parts is included, including any math delimiters($, $$) and LaTeX formatting.\n",
    "        -   Do not forget to include any images or figures that are part of the question stem, parts or solution.\n",
    "        -   Ensure no solution content is included in the `content` or `parts` fields.\n",
    "    \n",
    "    2.  **Output Format:**\n",
    "        -   You MUST output ONLY a single, raw, valid JSON string that matches the provided schema.\n",
    "        -   Do NOT include any explanations, comments, or markdown code blocks (like ```json).\n",
    "    \"\"\"\n",
    "\n",
    "example_seperate_parts_question = r\"\"\"\n",
    "    example:\n",
    "    [(0, \"Q1. find value of $x$ in the following equation:\"),\n",
    "    (1, \"i. $x + 1 = 2$\"),\n",
    "    (2, \"ii. $x - 1 = 5$\")]\n",
    "\n",
    "    should be converted to:\n",
    "    {\n",
    "        \"title\": \"suitable title\",\n",
    "        \"content_start\": 0,\n",
    "        \"content_end\": 0,\n",
    "        \"parts\": [\n",
    "            {\n",
    "                \"part_start\": 1,\n",
    "                \"part_end\": 1\n",
    "            },\n",
    "            {\n",
    "                \"part_start\": 2,\n",
    "                \"part_end\": 2\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "llm_task_seperate_parts_solution = r\"\"\"\n",
    "    1. **Content Extraction:**\n",
    "        -   From the input `full solution content`, identify the specific solution part that corresponds to the `target question part`, and place the start line and end line into `part_solution_start` and `part_solution_end`.\n",
    "        -   If the `target question part` is empty, identify the specific solution part that corresponds to the `full question stem`.\n",
    "        -   Use the `full question stem` and `full question parts` to help identify the specific solution part.\n",
    "        -   Ensure that the `target question part` is used to extract the specific solution part.\n",
    "        -   Be careful to ensure that everything related to the solution part is included, including any math delimiters($, $$) and LaTeX formatting.\n",
    "        -   Do not forget to include any images or figures that are part of the solution.\n",
    "\n",
    "    2.  **Output Format:**\n",
    "        -   You MUST output ONLY a single, raw, valid JSON string that matches the provided schema.\n",
    "        -   Do NOT include any explanations, comments, or markdown code blocks (like ```json).\n",
    "    \"\"\"\n",
    "\n",
    "def process_single_question(question_data):\n",
    "    \"\"\"Process a single question and its parts in parallel\"\"\"\n",
    "    question_idx, question = question_data\n",
    "    \n",
    "    # Initialize the output parser with the Set_Question schema.\n",
    "    question_parser = PydanticOutputParser(pydantic_object=Set_Question_Lines)\n",
    "\n",
    "    question_input: list[str] = question[\"question_content\"].splitlines()\n",
    "    solution_input: str = question[\"solution_content\"]\n",
    "    all_images = question[\"images\"]\n",
    "\n",
    "    # Prompt for the LLM to extract The question parts.\n",
    "    # Use the full question content and the images to extract the parts.\n",
    "    seperate_parts_question_prompt = f\"\"\"\n",
    "        Your task is to extract a JSON with the following structure exactly, ready to be parsed by a pydantic model:\n",
    "        {question_parser.get_format_instructions()}\n",
    "\n",
    "        {llm_task_seperate_parts_question}\n",
    "\n",
    "        {example_seperate_parts_question}\n",
    "\n",
    "        Full Solution Content:\n",
    "        {solution_input}\n",
    "\n",
    "        Full Question Content:\n",
    "        {list(enumerate(question_input))}\n",
    "\n",
    "        Return the JSON now.\n",
    "        \"\"\"\n",
    "    \n",
    "    # Process the question part\n",
    "    for attempt_idx in range(3):\n",
    "\n",
    "        response = llm_mini.invoke(seperate_parts_question_prompt)\n",
    "\n",
    "        try:\n",
    "            parsed_output_parts = question_parser.parse(response.content)\n",
    "            if len(parsed_output_parts.parts) < 1:\n",
    "                raise Exception(\"all questions should have at least 1 part.\")\n",
    "            print(f\"LLM response successfully parsed question {question_idx + 1}.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing LLM response as JSON for question {question_idx + 1}:\")\n",
    "            print(f\"Retrying... Attempt No.{attempt_idx + 1}\")\n",
    "            time.sleep(2)\n",
    "    else:\n",
    "        print(\"Final LLM Response:\")\n",
    "        print(response.content)\n",
    "        raise Exception(f\"Failed to parse LLM response as JSON after multiple attempts for question {question_idx + 1}.\")\n",
    "\n",
    "    # Convert from Set_Question_Lines to Set_Question\n",
    "    parsed_output_parts = convert_set_question_lines_to_set_question(parsed_output_parts, question_input, all_images)\n",
    "\n",
    "    # Process solution parts in parallel\n",
    "    def process_solution_part(part_data) -> Set_Solution_Part_Lines:\n",
    "        part_idx, part = part_data\n",
    "        solution_parser = PydanticOutputParser(pydantic_object=Set_Solution_Part_Lines)\n",
    "\n",
    "        target_solution_input: list[str] = solution_input.splitlines()\n",
    "\n",
    "        # Prompt for the LLM to extract The solution part.\n",
    "        # Use the full solution content and the part to extract the specific solution.\n",
    "        seperate_parts_solution_prompt = f\"\"\"\n",
    "            Your task is to extract a JSON with the following structure exactly, ready to be parsed by a pydantic model:\n",
    "            {solution_parser.get_format_instructions()}\n",
    "\n",
    "            {llm_task_seperate_parts_solution}\n",
    "\n",
    "            full question stem:\n",
    "            {parsed_output_parts.content}\n",
    "\n",
    "            full question parts:\n",
    "            {parsed_output_parts.parts}\n",
    "            \n",
    "            full solution content:\n",
    "            {list(enumerate(target_solution_input))}\n",
    "\n",
    "            target question part:\n",
    "            {part}\n",
    "            \"\"\"\n",
    "            \n",
    "        for attempt_idx in range(3):\n",
    "            \n",
    "            response = llm_mini.invoke(seperate_parts_solution_prompt)\n",
    "            \n",
    "            try:\n",
    "                parsed_output_solution_part = solution_parser.parse(response.content)\n",
    "                print(f\"LLM response successfully parsed solution for part {part_idx + 1} of question {question_idx + 1}.\")\n",
    "                return parsed_output_solution_part\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing LLM response as JSON for part {part_idx + 1} of question {question_idx + 1}:\")\n",
    "                print(f\"Retrying... Attempt No.{attempt_idx + 1}\")\n",
    "                time.sleep(2)\n",
    "        \n",
    "        else:\n",
    "            print(\"Final LLM Response:\")\n",
    "            print(response.content)\n",
    "            raise Exception(f\"Failed to parse LLM response as JSON after multiple attempts part {part_idx + 1} of question {question_idx + 1}:\")\n",
    "\n",
    "    # Process all parts in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        part_data_list = [(i, part) for i, part in enumerate(parsed_output_parts.parts)]\n",
    "        solutions_parts = list(executor.map(process_solution_part, part_data_list))\n",
    "\n",
    "    solutions_parts = convert_set_solution_lines_to_set_solution(\n",
    "        solutions_parts, \n",
    "        solution_input.splitlines()\n",
    "    )\n",
    "\n",
    "    # set_solution = Set_Solution(parts_solutions=solutions_parts)\n",
    "    return Set_Question_With_Solution(\n",
    "        question=parsed_output_parts,\n",
    "        solution=solutions_parts\n",
    "    )\n",
    "\n",
    "def extract_parts_question(questions_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the title and individual questions from a tutorial sheet.\n",
    "    Now processes questions in parallel while maintaining order.\n",
    "    \"\"\"\n",
    "    print(\"Extracting parts from the questions...\")\n",
    "\n",
    "    # Process all questions in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        question_data_list = [(i, q) for i, q in enumerate(questions_dict[\"questions\"])]\n",
    "        questions_in_parts = list(executor.map(process_single_question, question_data_list))\n",
    "    \n",
    "    print(\"Successfully extracted parts from all questions.\")\n",
    "    return Set_Lines(\n",
    "        name=questions_dict[\"name\"],\n",
    "        year=questions_dict[\"year\"],\n",
    "        questions=questions_in_parts\n",
    "    ).model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# remove the duplicated text for single part questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NoPartsQuestionModel(BaseModel):\n",
    "#     \"\"\"\n",
    "#     Represents a question without parts.\n",
    "#     \"\"\"\n",
    "#     hasParts: bool = Field(False, description=\"Indicates if the question has parts.\")\n",
    "\n",
    "# llm_task_remove_dupe = \"\"\"\n",
    "#     1.  **Task:**\n",
    "#         -   Check if the single part that the question has is the same as the full question content.\n",
    "#         -   If it is not, then remove the part and set `hasParts` to `False`.\n",
    "#         -   If it is, then set `hasParts` to `True`.\n",
    "        \n",
    "#     2.  **Output Format:**\n",
    "#         -   You MUST output ONLY a single, raw, valid JSON string that matches the provided schema.\n",
    "#         -   Do NOT include any explanations, comments, or markdown code blocks (like ```json).\n",
    "#     \"\"\"\n",
    "# def llm_remove_dupe_part(content: str, part: str) -> bool:\n",
    "#     return content == part\n",
    "\n",
    "def dupe_text_reduce(questions_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Reduces duplicate text in the questions content and its parts.\n",
    "    \"\"\"\n",
    "    for question in questions_dict[\"questions\"]:\n",
    "        parts = question[\"parts\"]\n",
    "        if len(parts) == 1 and parts[0] == question[\"content\"]:\n",
    "            # If the only part is the same as the content, remove the part and set hasParts to False.\n",
    "            question[\"parts\"][0] = \"\"\n",
    "    \n",
    "    return questions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_to_json(md_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the title and individual questions from a tutorial sheet.\n",
    "    \n",
    "    Args:\n",
    "        md_content (str): The content of a set.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the keys \"name\" and \"exercise\".\n",
    "              If parsing fails, returns None.\n",
    "    \"\"\"\n",
    "\n",
    "    md_content_lines = md_content.splitlines()\n",
    "\n",
    "    # corrected_md_content = correct_mistakes_in_markdown(md_content)\n",
    "    # print(\"Markdown content corrected for spelling, grammar, and structure.\")\n",
    "\n",
    "    questions_dict = llm_extract_questions_lines(md_content_lines)\n",
    "    print((json.dumps(questions_dict)))\n",
    "\n",
    "    extracted_dict = extract_parts_question(questions_dict)\n",
    "    print(json.dumps(extracted_dict))\n",
    "\n",
    "    return dupe_text_reduce(extracted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_json_question_set = md_to_json(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Displaying questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title\n",
    "title = full_json_question_set[\"name\"] + \" \" + full_json_question_set[\"year\"]\n",
    "\n",
    "# Print the title\n",
    "print(f\"Title: {title}\\n\")\n",
    "\n",
    "# Extract questions\n",
    "questions = full_json_question_set[\"questions\"]\n",
    "\n",
    "# Loop over and print each question\n",
    "for question_idx, question in enumerate(questions, start=1):\n",
    "    print(f\"**Question {question_idx}**:\\n{question.get('title')}\\n\")\n",
    "    print(f\"Content: {question.get('content')}\\n\")\n",
    "    for part_idx, (part_question, part_answer) in enumerate(zip(question.get(\"parts\", []), question.get(\"parts_solutions\", [])), start=1):\n",
    "        print(f\"Question {question_idx}:\")\n",
    "        print(f\"- Subquestion {part_idx}: {part_question}\")\n",
    "        print(f\"- Worked Solution {part_idx}: {part_answer}\")\n",
    "        print(\"\\n\")\n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# in2lambda to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = full_json_question_set[\"questions\"]\n",
    "\n",
    "in2lambda_questions = []\n",
    "\n",
    "# Loop over all questions and question_answers and use in2lambda API to create a JSON.\n",
    "for question_idx, question_dict in enumerate(questions, start=1):\n",
    "    parts = []\n",
    "\n",
    "    for part_question, part_solution in zip(question_dict.get(\"parts\", []), question_dict.get(\"parts_solutions\", [])):\n",
    "        part_obj = Part(\n",
    "            text=part_question,\n",
    "            worked_solution=part_solution\n",
    "        )\n",
    "        parts.append(part_obj)\n",
    "\n",
    "    # Handle image paths - ensure they exist\n",
    "    image_paths = []\n",
    "    for img in question_dict.get(\"images\", []):\n",
    "        if img.startswith(\"http\"):\n",
    "            # Skip URLs that weren't processed\n",
    "            continue\n",
    "        full_path = f\"{media_path}/{img}\"\n",
    "        if Path(full_path).exists():\n",
    "            image_paths.append(full_path)\n",
    "        else:\n",
    "            print(f\"Warning: Image file not found: {full_path}\")\n",
    "\n",
    "    question = Question(\n",
    "        title=question_dict.get(\"title\", f\"Question {question_idx}\"),\n",
    "        main_text=question_dict.get(\"content\", \"\"),\n",
    "        parts=parts,\n",
    "        images=image_paths\n",
    "    )\n",
    "    in2lambda_questions.append(question)\n",
    "\n",
    "try:\n",
    "    Module(in2lambda_questions).to_json(f\"{output_path}/out\")\n",
    "    print(\"JSON output successfully created.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating JSON output: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
