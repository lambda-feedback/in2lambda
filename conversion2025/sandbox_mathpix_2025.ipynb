{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables from .env file.\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# scanning/processing the initial pdf into markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATHPIX_API_KEY = os.getenv(\"MATHPIX_API_KEY\")\n",
    "MATHPIX_APP_ID = os.getenv(\"MATHPIX_APP_ID\")\n",
    "\n",
    "def pdf_to_markdown(source_path: str, result_path: str):\n",
    "    ''' \n",
    "    converts the pdf at `source_path` to a markdown file at `result_path` using Mathpix API.\n",
    "    '''\n",
    "    # Upload PDF to Mathpix and returns a Markdown file with the content.\n",
    "    with open(source_path, \"rb\") as file:\n",
    "        r = requests.post(\n",
    "            \"https://api.mathpix.com/v3/pdf\",   \n",
    "            headers={\n",
    "                \"app_id\": MATHPIX_APP_ID,\n",
    "                \"app_key\": MATHPIX_API_KEY,\n",
    "            },\n",
    "            files={\"file\": file},\n",
    "        )\n",
    "        pdf_id = r.json()[\"pdf_id\"]\n",
    "        print(\"PDF ID:\", pdf_id)\n",
    "        print(\"Response:\", r.json())\n",
    "\n",
    "        url = f\"https://api.mathpix.com/v3/pdf/{pdf_id}.md\"\n",
    "        headers = {\n",
    "            \"app_id\": MATHPIX_APP_ID,\n",
    "            \"app_key\": MATHPIX_API_KEY,\n",
    "        }\n",
    "\n",
    "        max_retries = 10\n",
    "        retry_delay = 5  # seconds\n",
    "        for attempt in range(max_retries):\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                # Save the result if the request is successful\n",
    "                with open(result_path, \"w\") as f:\n",
    "                    f.write(response.text)\n",
    "                print(\"Downloaded MD successfully.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Attempt {attempt + 1}/{max_retries}: Processing not complete. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "        else:\n",
    "            print(\"Failed to retrieve processed PDF after multiple attempts:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# setting up the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"conversion_content\"\n",
    "output_path = f\"{folder_path}/out\"\n",
    "media_path = f\"{output_path}/media\"\n",
    "\n",
    "Path(media_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "source_path = f\"{folder_path}/example.pdf\"\n",
    "result_path = f\"{folder_path}/example.md\"\n",
    "\n",
    "pdf_to_markdown(source_path, result_path)\n",
    "with open(result_path, \"r\") as f:\n",
    "    md_content = f.read()\n",
    "\n",
    "# Print out a summary.\n",
    "print(\"Markdown text: \")\n",
    "print(f\"  {result_path}: {len(md_content)} characters\")\n",
    "print(\"Markdown text: \")\n",
    "print(f\"  {result_path}: {md_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# downlaoding extracted images from Mathpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the figures from the paper and answers.\n",
    "def extract_figures_from_text(text): #, ans=False):\n",
    "    \"\"\"\n",
    "    Extracts figures from the text using regex.\n",
    "    Finds figure references and their descriptions.\n",
    "    \"\"\"\n",
    "    figures = {}\n",
    "    # Regex to match figure references and their descriptions\n",
    "    pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    print(f\"Matches found: {matches}\")\n",
    "    \n",
    "    for match in matches:\n",
    "        url = match\n",
    "        url = url.strip()\n",
    "        figure_caption_pattern = rf'\\({re.escape(url)}\\)\\s*-?\\s*Figure\\s+(Q\\d+)\\s*-\\s*(.+?)\\n'\n",
    "        caption_match = re.search(figure_caption_pattern, text)\n",
    "\n",
    "        if caption_match:\n",
    "            title, description = caption_match.groups()\n",
    "            print(\"Caption match found\")\n",
    "        else:\n",
    "            title, description = \"\", \"\"\n",
    "\n",
    "        if url.startswith(\"http\"):\n",
    "            # Download the image and save it to a file\n",
    "            image = Image.open(requests.get(url, stream=True).raw)\n",
    "            # Create a figure name based on the URL\n",
    "            fig_name = os.path.basename(url)\n",
    "            figures[fig_name] = {\n",
    "                \"image\": image,\n",
    "                \"title\": title.strip(),\n",
    "                \"label\": description.strip(),\n",
    "                \"url\": url,\n",
    "                \"local_path\": \"\",\n",
    "                # \"answerFile\": ans\n",
    "            }\n",
    "    return figures\n",
    "\n",
    "# a dictionary storing information on the figures\n",
    "figures = extract_figures_from_text(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# saving the images locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figures_to_path(figures):\n",
    "    for idx, (fig_name, fig_info) in enumerate(figures.items()):\n",
    "        print(f\"FIGURE Title='{fig_info['title']}', Label='{fig_info['label']}', URL='{fig_info['url']}'\")\n",
    "        # image_name = f\"figure_{fig_info['title']}.png\" #{\"_ans\" if fig_info[\"answerFile\"] else \"\"}.png\"\n",
    "        # if image_name in os.listdir(f\"{set_path}media/\"):\n",
    "        #     image_name = f\"figure_{fig_info['title']}_{idx}.png\" #{\"_ans\" if fig_info[\"answerFile\"] else \"\"}.png\"\n",
    "        end_location = fig_name.index(\"?\")\n",
    "        image_name = f\"{idx}_{fig_name[:end_location]}\"\n",
    "        fig_info[\"local_path\"] = image_name\n",
    "        fig_info[\"image\"].save(f\"{media_path}{fig_info['local_path']}\")\n",
    "\n",
    "save_figures_to_path(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# replacing url for images with local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_figures_in_markdown(md_content, figures):\n",
    "    #replace the image URLs in the markdown content with local paths\n",
    "    for fig_name, fig_info in figures.items():\n",
    "        md_content = md_content.replace(fig_info[\"url\"], fig_info[\"local_path\"])\n",
    "        print(f\"Replaced {fig_info['url']} with {fig_info['local_path']} in markdown content.\")\n",
    "    # Save the modified markdown content to a file\n",
    "    with open(f\"{folder_path}/example.md\", \"w\") as f:\n",
    "        f.write(md_content)\n",
    "\n",
    "replace_figures_in_markdown(md_content, figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Initialising llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM via LangChain.\n",
    "llm = ChatOpenAI(\n",
    "            model=os.environ['OPENAI_MODEL'],\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Extract Questions and Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the tutorial output.\n",
    "class Set_Question(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the exercise (only the text, no numbering)\")\n",
    "    content: str = Field(..., description=\"Content of the exercise (no exercise title, no subquestions)\")\n",
    "    subquestions: list[str] = Field(..., description=\"List of subquestions within the exercise (only the text, no numbering)\")\n",
    "    \n",
    "class Set_Answer(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the exercise (only the text, no numbering)\")\n",
    "    workedSolutions: list[str] = Field(..., description=\"List of worked solution to subquestions within the exercise (no numbering or counting)\")\n",
    "\n",
    "class Set(BaseModel):\n",
    "    name: str = Field(..., description=\"Title of the set\")\n",
    "    year: str = Field(..., description=\"Year of the set\")\n",
    "    exercise: list[Set_Question] = Field(..., description=\"List of exercises in the set\")\n",
    "    workedSolution: list[Set_Answer] = Field(..., description=\"List of worked solutions for the exercises in the set\")\n",
    "\n",
    "def extract_tutorial_questions(doc_page_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the title and individual exercises from a tutorial sheet.\n",
    "\n",
    "    This function takes the content of a tutorial sheet (doc.page_content), constructs a prompt\n",
    "    instructing the LLM to infer the tutorial title and to split the text into separate questions.\n",
    "    The output must be a valid JSON string with the following structure:\n",
    "    \n",
    "    {\n",
    "        \"name\": \"<title of tutorial>\",\n",
    "        \"year\": \"<year of tutorial>\",\n",
    "        \"exercise\": [\n",
    "            { title: \"exercise text 1\", content: \"content text exercise 1\", subquestions: [\"subquestion text 1\", \"subquestion text 2\", ...],\n",
    "            { title: \"exercise text 2\", content: \"content text exercise 2\", subquestions: [\"subquestion text 1\", \"subquestion text 2\", ...],\n",
    "            ...\n",
    "        ]\n",
    "        \"workedSolution\": [\n",
    "            { title: \"exercise text 1\", workedSolutions: [\"solution text 1\", \"solution text 2\", ...] },\n",
    "            { title: \"exercise text 2\", workedSolutions: [\"solution text 1\", \"solution text 2\", ...] },\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    the original text of the exercises. The function returns a dictionary parsed from the JSON output.\n",
    "    if any of the text mentions a figure/diagram, then also find the figure and add it to the content of the exercise.\n",
    "    \n",
    "    Args:\n",
    "        doc_page_content (str): The content of a set.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the keys \"name\" and \"exercise\".\n",
    "              If parsing fails, returns None.\n",
    "    \"\"\"\n",
    "    # Initialize the output parser with the Tutorial schema.\n",
    "    parser = PydanticOutputParser(pydantic_object=Set)\n",
    "\n",
    "    # Construct the prompt, appending the parser's format instructions.\n",
    "    prompt = f\"\"\"\n",
    "        IMPORTED_SET\n",
    "        ```markdown\n",
    "        {doc_page_content}\n",
    "        ```\n",
    "\n",
    "        IMPORTED_SET is a set of questions. It may or may not include reference solutions.\n",
    "        Infer the title of the set from the content, if no suitable name found, just leave as Unnamed Set, and extract each individual question as a separate string.\n",
    "        Do not modify the text of the exercises. \n",
    "        it is important to only use $...$ for math expressions.\n",
    "\n",
    "        If the exercise mentions figures/diagrams, then find the diagram (the local path) that it is talking about,\n",
    "        and include it in the content of the exercise.\n",
    "\n",
    "        If the exercise mentions tables, then include the table in the content.\n",
    "\n",
    "        Ensure that there is a workedSolution for each exercise, which should have the same title and a list of solutions that matches the subquestions.\n",
    "\n",
    "        Return a valid JSON string with the following structure:\n",
    "        {parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "\n",
    "    # Call the LLM\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Debug: print the raw LLM response\n",
    "    print(\"Raw LLM Response:\")\n",
    "    print(response)\n",
    "\n",
    "    try:\n",
    "        # Parse the response using the output parser.\n",
    "        parsed_output = parser.parse(response.content)\n",
    "        # For Pydantic v2, use model_dump() to convert the model to a dictionary.\n",
    "        return parsed_output.model_dump()\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing LLM response as JSON:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_tutorial = extract_tutorial_questions(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title\n",
    "title = imported_tutorial[\"name\"] + \" \" + imported_tutorial[\"year\"]\n",
    "\n",
    "# Print the title\n",
    "print(f\"Title: {title}\\n\")\n",
    "\n",
    "# Extract questions\n",
    "questions = imported_tutorial[\"exercise\"]\n",
    "solutions = imported_tutorial[\"workedSolution\"]\n",
    "\n",
    "# Loop over and print each question\n",
    "for idx1, (question, solution) in enumerate(zip(questions, solutions), start=1):\n",
    "    print(f\"**Question {idx1}**:\\n{question.get(\"title\")}\\n\")\n",
    "    print(f\"Content: {question.get(\"content\")}\\n\")\n",
    "    for idx2, (subquestion, subanswer) in enumerate(zip(question.get(\"subquestions\", []), solution.get(\"workedSolutions\", [])), start=1):\n",
    "        print(f\"Question {idx1}:\")\n",
    "        print(f\"- Subquestion {idx2}: {subquestion}\")\n",
    "        print(f\"- Worked Solution {idx2}: {subanswer}\")\n",
    "        print(\"\\n\")\n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Form JSON Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nested Pydantic models based on the JSON schema.\n",
    "class WorkedSolution(BaseModel):\n",
    "    content: str = Field(..., description=\"Worked solution content\")\n",
    "    title: str = Field(..., description=\"Worked solution title\")\n",
    "    children: list = []\n",
    "\n",
    "class Part(BaseModel):\n",
    "    answerContent: str = Field(..., description=\"Part answer text\")\n",
    "    content: str = Field(..., description=\"Part content text\")\n",
    "    orderNumber: int = Field(..., description=\"The order number of this part\")\n",
    "    responseAreas: list = Field(..., description=\"List of response areas\")\n",
    "    tutorial: list = Field(..., description=\"List of tutorial items\")\n",
    "    workedSolution: WorkedSolution = Field(..., description=\"Worked solution details\")\n",
    "\n",
    "class QuestionJson(BaseModel):\n",
    "    orderNumber: int = Field(..., description=\"The order number of the question\")\n",
    "    displayFinalAnswer: bool = Field(..., description=\"Flag to display the final answer\")\n",
    "    displayStructuredTutorial: bool = Field(..., description=\"Flag to display the structured tutorial\")\n",
    "    displayWorkedSolution: bool = Field(..., description=\"Flag to display the worked solution\")\n",
    "    masterContent: str = Field(..., description=\"Top level question content\")\n",
    "    parts: list[Part] = Field(..., description=\"List of question parts\")\n",
    "    publish: bool = Field(..., description=\"Publish flag\")\n",
    "    title: str = Field(..., description=\"Question title\")\n",
    "\n",
    "def create_question_json(question: str, solution: str) -> dict:\n",
    "    # Initialize the output parser using the defined Pydantic model.\n",
    "    parser = PydanticOutputParser(pydantic_object=QuestionJson)\n",
    "\n",
    "    # Minimum JSON template to guide the model. (Used as context.)\n",
    "    minimum_json_template = r'''{\n",
    "      \"orderNumber\": 0,\n",
    "      \"displayFinalAnswer\": true,\n",
    "      \"displayStructuredTutorial\": true,\n",
    "      \"displayWorkedSolution\": true,\n",
    "      \"displayChatbot\": false,\n",
    "      \"masterContent\": \"Top level question here\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"answerContent\": \"final answer here corresponding the part, is no answer found, leave empty\",\n",
    "          \"content\": \"part question text here, if only one part, then leave empty\",\n",
    "          \"orderNumber\": 0,\n",
    "          \"responseAreas\": [],\n",
    "          \"tutorial\": [],\n",
    "          \"workedSolution\": {\n",
    "            \"content\": \"Part worked solution here\",\n",
    "            \"title\": \"\",\n",
    "            \"children\": []\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"publish\": false,\n",
    "      \"title\": \"Question title here\"\n",
    "    }'''\n",
    "\n",
    "    # Construct the prompt, appending the parser's format instructions.\n",
    "    question_prompt = f'''\n",
    "      JSON_TEMPLATE\n",
    "      ```json\n",
    "      {minimum_json_template}\n",
    "      ```\n",
    "\n",
    "      IMPORTED_QUESTION\n",
    "      ```markdown\n",
    "      {question}\n",
    "      ```\n",
    "\n",
    "      IMPORTED_SOLUTION\n",
    "      ```markdown\n",
    "      {solution}\n",
    "      ```\n",
    "\n",
    "      Preserve the markdown math formatting to use $...$ for math expressions. Do not modify the original text of the question.\n",
    "\n",
    "      Infer the final answer and put it in the answerContent field of the part. \n",
    "      The worked solution should be in the workedSolution.content field.\n",
    "\n",
    "      If you cannot find a suitable text for any of the sections, leave it empty.\n",
    "\n",
    "      {parser.get_format_instructions()}\n",
    "      '''\n",
    "\n",
    "    # Invoke the language model.\n",
    "    response = llm.invoke(question_prompt)\n",
    "\n",
    "    try:\n",
    "        # Parse the response using the output parser.\n",
    "        parsed_output = parser.parse(response.content)\n",
    "        return parsed_output.model_dump()  # Return as a dictionary.\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON from LLM response:\", e)\n",
    "        print(\"LLM response:\", response.content)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = imported_tutorial[\"exercise\"]\n",
    "solutions = imported_tutorial[\"workedSolution\"]\n",
    "\n",
    "\n",
    "# Loop over all questions and question_answers and print each question\n",
    "for idx, (question, solution) in enumerate(zip(questions, solutions), start=1):\n",
    "    print(f\"**Question {idx}**:\\n{question}\\n\")\n",
    "    # print(f\"**Question Answers {idx}**:\\n{question_ans}\\n\")\n",
    "\n",
    "    print(\"INFO: Mapping question in markdown into JSON\")\n",
    "    question_json = create_question_json(question,solution)\n",
    "    question_json[\"orderNumber\"] = idx-1\n",
    "    print(f\"INFO: JSON {idx}:\\n{question_json}\\n\")\n",
    "    \n",
    "    # print(\"INFO: Get figures\")\n",
    "    # updated_question_json = add_figure_references_to_questions(figures, question_json)\n",
    "    # updated_question_json = add_local_figures_to_questions(figures, question_json)\n",
    "    updated_question_json = question_json\n",
    "\n",
    "    question_name = updated_question_json[\"title\"].replace(\" \", \"_\")\n",
    "    question_index = f\"{(idx-1):03}\" \n",
    "    filename = f\"{output_path}/question_{question_index}_{question_name}.json\"\n",
    "    print(f\"INFO: writing {filename}\")\n",
    "    open(filename, \"w\").write(json.dumps(updated_question_json, indent=2))\n",
    "    \n",
    "    # break # breaking here as just doing quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
