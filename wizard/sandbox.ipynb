{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_math_to_markdown(text: str, llm) -> str:\n",
    "    \"\"\"\n",
    "    Uses the LLM to convert scientific text (including mathematics)\n",
    "    into markdown (e.g. wrapping inline math with $ or display math with $$).\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Convert the following scientific text with mathematics into markdown format. \"\n",
    "        \"Ensure that all mathematical expressions are properly formatted using inline ($...$) \"\n",
    "        \"or display ($$...$$) markdown syntax as appropriate.\\n\\n\"\n",
    "        f\"{text}\"\n",
    "    )\n",
    "    markdown_text = llm.invoke(prompt)\n",
    "    return markdown_text.content\n",
    "\n",
    "\n",
    "def extract_caption_from_bbox(page, bbox, threshold: float = 50) -> str:\n",
    "    caption_candidates = []\n",
    "    # Iterate over each block.\n",
    "    for block in page.get_text(\"blocks\"):\n",
    "        # Unpack the first five elements and ignore the rest.\n",
    "        bx0, by0, bx1, by1, text, *_ = block\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        # If the block's top coordinate is just below the image bounding box.\n",
    "        if by0 >= bbox[3] and (by0 - bbox[3]) < threshold:\n",
    "            caption_candidates.append((by0, text.strip()))\n",
    "    if caption_candidates:\n",
    "        # Return the caption of the block closest to the image.\n",
    "        caption_candidates.sort(key=lambda t: t[0])\n",
    "        return caption_candidates[0][1]\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_caption(caption: str) -> (str, str):\n",
    "    \"\"\"\n",
    "    Given a caption string, try to parse out a title and label.\n",
    "    For example, if the caption includes tokens like “Title: …” or “Label: …”.\n",
    "    \"\"\"\n",
    "    title = \"\"\n",
    "    label = \"\"\n",
    "    m_title = re.search(r\"Title\\s*[:\\-]\\s*(.+?)(,|$)\", caption, re.IGNORECASE)\n",
    "    if m_title:\n",
    "        title = m_title.group(1).strip()\n",
    "    m_label = re.search(r\"Label\\s*[:\\-]\\s*(.+?)(,|$)\", caption, re.IGNORECASE)\n",
    "    if m_label:\n",
    "        label = m_label.group(1).strip()\n",
    "    return title, label\n",
    "\n",
    "\n",
    "def get_figure_name(caption: str, default_name: str) -> str:\n",
    "    \"\"\"\n",
    "    If the caption contains a reference like “Figure 2”, return a name based on that.\n",
    "    Otherwise return the provided default name.\n",
    "    \"\"\"\n",
    "    if caption:\n",
    "        m_fig = re.search(r\"Figure\\s*(\\d+)\", caption, re.IGNORECASE)\n",
    "        if m_fig:\n",
    "            return f\"Figure_{m_fig.group(1)}\"\n",
    "    return default_name\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path: str):\n",
    "    \"\"\"\n",
    "    Reads a PDF file, extracts its text (with mathematics converted to markdown)\n",
    "    and extracts images (with associated captions parsed for title and label).\n",
    "    \n",
    "    Returns a LangChain Document whose page_content is the markdown text and whose\n",
    "    metadata includes a dictionary 'figures' mapping figure names to a dict:\n",
    "      { \"image\": <PIL.Image>, \"title\": <str>, \"label\": <str> }.\n",
    "    \"\"\"\n",
    "    # 1. Extract the main text using a loader optimized for scientific content.\n",
    "    text_loader = UnstructuredPDFLoader(pdf_path)\n",
    "    docs = text_loader.load()\n",
    "    combined_text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # 2. Use the LLM to convert mathematics in the text to proper markdown.\n",
    "    markdown_text = convert_math_to_markdown(combined_text, llm)\n",
    "    \n",
    "    # 3. Extract images and associated metadata using PyMuPDF.\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    figures = {}\n",
    "    \n",
    "    for page_num in range(len(pdf_doc)):\n",
    "        page = pdf_doc[page_num]\n",
    "        # Use the \"dict\" interface for richer info.\n",
    "        page_dict = page.get_text(\"dict\")\n",
    "        blocks = page_dict.get(\"blocks\", [])\n",
    "\n",
    "        for block in blocks:\n",
    "            if isinstance(block, dict) and block.get(\"type\") == 1:\n",
    "                xref = block.get(\"image\")\n",
    "                bbox = block.get(\"bbox\")\n",
    "                if not xref:\n",
    "                    continue\n",
    "\n",
    "                # Check the type of xref.\n",
    "                if isinstance(xref, int):\n",
    "                    # xref is valid; extract the image using PyMuPDF.\n",
    "                    base_image = pdf_doc.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                elif isinstance(xref, bytes):\n",
    "                    # xref already contains the image bytes (inline image).\n",
    "                    image_bytes = xref\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Open the image with PIL.\n",
    "                img_obj = Image.open(BytesIO(image_bytes))\n",
    "                \n",
    "                # Try to extract a caption near the image.\n",
    "                caption = extract_caption_from_bbox(page, bbox)\n",
    "                title, label = (\"\", \"\")\n",
    "                if caption:\n",
    "                    title, label = parse_caption(caption)\n",
    "                default_fig_name = f\"page{page_num+1}_img_{xref if isinstance(xref, int) else 'inline'}\"\n",
    "                fig_name = get_figure_name(caption, default_fig_name) if caption else default_fig_name\n",
    "                figures[fig_name] = {\"image\": img_obj, \"title\": title, \"label\": label}\n",
    "    \n",
    "    pdf_doc.close()\n",
    "    \n",
    "    # 4. Create and return a LangChain Document.\n",
    "    metadata = {\"figures\": figures}\n",
    "    final_doc = Document(page_content=markdown_text, metadata=metadata)\n",
    "    return final_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted figures:\n",
      "  page1_img_inline: Title='', Label=''\n",
      "  page2_img_inline: Title='', Label=''\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file.\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the Azure OpenAI LLM via LangChain.\n",
    "llm = AzureChatOpenAI(deployment_name=\"o1\")\n",
    "\n",
    "pdf_file_path = \"example/ExampleSetExported.pdf\"\n",
    "doc = process_pdf(pdf_file_path)\n",
    "\n",
    "# Print out a summary.\n",
    "# print(\"Markdown text: \")\n",
    "# print(doc.page_content)\n",
    "\n",
    "# Needs to be improved to infer name/label/caption based on context.\n",
    "figures = doc.metadata.get(\"figures\", {})\n",
    "print(\"\\nExtracted figures:\")\n",
    "\n",
    "Path(\"media\").mkdir(exist_ok=True)\n",
    "for idx, (fig_name, fig_info) in enumerate(figures.items()):\n",
    "    print(f\"  {fig_name}: Title='{fig_info['title']}', Label='{fig_info['label']}'\")\n",
    "    # Save each image as a PNG file with a sequential name: figure_0.png, figure_1.png, etc.\n",
    "    fig_info[\"image\"].save(f\"media/figure_{idx}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the tutorial output.\n",
    "class Tutorial(BaseModel):\n",
    "    name: str = Field(..., description=\"Title of the tutorial\")\n",
    "    questions: list[str] = Field(..., description=\"List of tutorial questions\")\n",
    "\n",
    "def extract_tutorial_questions(doc_page_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the title and individual questions from a tutorial sheet.\n",
    "\n",
    "    This function takes the content of a tutorial sheet (doc.page_content), constructs a prompt\n",
    "    instructing the LLM to infer the tutorial title and to split the text into separate questions.\n",
    "    The output must be a valid JSON string with the following structure:\n",
    "    \n",
    "    {\n",
    "        \"name\": \"<title of tutorial>\",\n",
    "        \"questions\": [\n",
    "            \"question text 1\",\n",
    "            \"question text 2\",\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    The tutorial sheet (IMPORTED_TUTORIAL) may contain reference solutions; do not alter\n",
    "    the original text of the questions. The function returns a dictionary parsed from the JSON output.\n",
    "    \n",
    "    Args:\n",
    "        doc_page_content (str): The content of the tutorial sheet.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the keys \"name\" and \"questions\".\n",
    "              If parsing fails, returns None.\n",
    "    \"\"\"\n",
    "    # Initialize the output parser with the Tutorial schema.\n",
    "    parser = PydanticOutputParser(pydantic_object=Tutorial)\n",
    "\n",
    "    # Construct the prompt, appending the parser's format instructions.\n",
    "    prompt = f\"\"\"\n",
    "        IMPORTED_TUTORIAL\n",
    "        ```markdown\n",
    "        {doc_page_content}\n",
    "        ```\n",
    "\n",
    "        IMPORTED_TUTORIAL is a tutorial sheet with several questions. It may or may\n",
    "        not include reference solutions. Please infer the title of the tutorial from\n",
    "        the content, and extract each individual question as a separate string. Do\n",
    "        not modify the text of the questions.\n",
    "\n",
    "        Return a valid JSON string with the following structure:\n",
    "        {parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "\n",
    "    # Call the LLM\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Debug: print the raw LLM response\n",
    "    # print(\"Raw LLM Response:\")\n",
    "    # print(response)\n",
    "\n",
    "    try:\n",
    "        # Parse the response using the output parser.\n",
    "        parsed_output = parser.parse(response.content)\n",
    "        # For Pydantic v2, use model_dump() to convert the model to a dictionary.\n",
    "        return parsed_output.model_dump()\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing LLM response as JSON:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_tutorial = extract_tutorial_questions(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: MECH50010 Fluid Mechanics 2 Problem Set #1\n",
      "\n",
      "**Question 1**:\n",
      "### 1.1 Hydraulic scale\n",
      "\n",
      "**HII 5-10 mins**\n",
      "\n",
      "This is a gentle warm-up question to get into the swing of things after a long summer.\n",
      "\n",
      "A piston of diameter $D = 0.1\\,\\mathrm{m}$ is fitted inside a U-shaped tube filled with liquid mercury (with density $\\rho_{\\mathrm{Hg}} = 13{,}540\\,\\mathrm{kg\\,m}^{-3}$), as shown by the sketch below. The mercury rises by $h = 1\\,\\mathrm{mm}$ under the weight of the piston.\n",
      "\n",
      "1. (a) What is the mass, $m$, of the piston?\n",
      "\n",
      "2. (b) If this result is to be used to measure the piston’s weight, what would you do to improve the accuracy of the measurement?\n",
      "\n",
      "---\n",
      "\n",
      "----------------------------------------\n",
      "**Question 2**:\n",
      "### 1.2 Friction on a plate\n",
      "\n",
      "**HHI 15-20 mins**\n",
      "\n",
      "This question is to refresh your use of control volumes, which were used in ME1 and will be used often in ME2. A fluid with density $\\rho = 800\\,\\mathrm{kg\\,m}^{-3}$ flows at $U_0 = 3\\,\\mathrm{m\\,s}^{-1}$ over a flat plate of length $L = 1\\,\\mathrm{m}$ and width $W = 1\\,\\mathrm{m}$. At the trailing edge, the boundary-layer thickness is $\\delta = 25\\,\\mathrm{mm}$. Assume the velocity profile at the trailing edge to be linear (as shown in the figure) and the flow to be two-dimensional.\n",
      "\n",
      "1. (a) Compute the mass flow rate across the top surface of the control volume (noted ab in the figure).\n",
      "\n",
      "2. (b) Determine the drag force on the plate.\n",
      "\n",
      "---\n",
      "\n",
      "----------------------------------------\n",
      "**Question 3**:\n",
      "### 1.3 Towing a submarine\n",
      "\n",
      "**HHI 15-20 mins**\n",
      "\n",
      "This is another revision question from ME1, for those who need extra practice.\n",
      "\n",
      "A submerged submarine is towed horizontally at a steady speed $U$ in deep still water. An axially-symmetrical wake is formed behind the submarine in which the water velocity may be assumed to vary linearly from $U$ on the axis to zero at a radius $R$. The variation of the water pressure with depth may be assumed to be unaffected by the presence of the submarine. The density of the water is $\\rho$. Using a control-volume analysis, we want to find the required power to tow the submarine. For both choices of control volumes (A and B as shown above), derive an expression for:\n",
      "\n",
      "1. (a) The drag force $F$ of the submarine.\n",
      "\n",
      "2. (b) The power $P$ required to tow the submarine.\n",
      "\n",
      "---\n",
      "\n",
      "----------------------------------------\n",
      "**Question 4**:\n",
      "### 1.4 Molecules, particles, and continuum\n",
      "\n",
      "**HHI 20-25 mins**\n",
      "\n",
      "This question bridges ME1 and ME2, exploring the continuum hypothesis and the definition of a fluid particle.\n",
      "\n",
      "Let us consider still air in standard atmospheric conditions at ground level: $T_0 = 273.15\\,\\mathrm{K}$, $p_0 = 1.00\\,\\mathrm{bar}$. For simplicity, we assume air to be made of exactly the same diatomic molecules (a fair assumption) with molar mass $M = 28.8\\,\\mathrm{g\\,mol}^{-1}$. Each molecule is modeled as a hard sphere of diameter $\\sigma = 1.54 \\times 10^{-10}\\,\\mathrm{m}$. Consequently, air is considered to behave as an ideal gas. The Avogadro number is $N_A = 6.02 \\times 10^{23}\\,\\mathrm{mol}^{-1}$, and the universal gas constant is $\\tilde{R} = 8.314\\,\\mathrm{J\\,(mol \\cdot K)}$.\n",
      "\n",
      "1. (a) Calculate the number of molecules $n_0$ per unit volume.\n",
      "\n",
      "   (Note that in the response area below you can use exponential notation, e.g. 5.7e13 m^(-3) is an acceptable input — but an incorrect answer!)\n",
      "\n",
      "2. (b) It can be shown that the mean-free path in the hard-sphere model is\n",
      "\n",
      "   $$\\ell = \\frac{1}{\\sqrt{2\\pi\\,\\sigma^2\\,n}}.$$\n",
      "\n",
      "   Give its numerical value at ground level. If we are concerned with an engineering problem with length-scale $L \\approx 1\\,\\mathrm{m}$, what should the size of a fluid particle be?\n",
      "\n",
      "3. (c) Aircraft designers assume air to be a continuum medium. The density of air decreases with altitude as follows:\n",
      "\n",
      "   $$\\rho(z) = \\rho_0 \\left[ 1 - \\frac{g}{c_p\\,T_0} \\, z \\right]^{\\tfrac{1}{\\gamma -1}},$$\n",
      "\n",
      "   where $\\rho_0, T_0$ are the density and temperature at ground level and $z$ is the altitude measured from the ground. The gravitational acceleration is $g = 9.8\\,\\mathrm{m\\,s}^{-2}$, the specific heat at constant pressure is $c_p = 0.83\\,\\mathrm{kJ\\,(kg \\cdot K)}$ and the heat capacity ratio is $\\gamma = \\tfrac{7}{5}$.\n",
      "\n",
      "   As density decreases, the mean-free path is expected to increase. Therefore, there must be a height $H$ from which the continuum assumption is no longer valid. Using the results and assumptions from parts (a) and (b), and assuming that the aircraft designer is concerned with scales of order one meter, is it reasonable to use the continuum model for an airliner at 10 km altitude? Show your working.\n",
      "\n",
      "   • Yes\n",
      "   • No\n",
      "\n",
      "---\n",
      "\n",
      "----------------------------------------\n",
      "**Question 5**:\n",
      "### 1.5 Frames of reference\n",
      "\n",
      "**HII 3-5 mins**\n",
      "\n",
      "A simple test of your basic understanding of Eulerian and Lagrangian frames of reference (content covered in Lecture 1 in ME2).\n",
      "\n",
      "1. (a) What is $\\vec{\\chi}(t)$?\n",
      "\n",
      "   - A fixed location, $x$, in space for all time, $(t)$.  \n",
      "   - The Lagrange multiplier in time, $t$.  \n",
      "   - The location of a particle, $p$, at time, $t$.  \n",
      "   - The relation between velocity, $p$, and space, $x$, at time, $t$.  \n",
      "\n",
      "2. (b) When does $\\vec{u}(\\vec{x}, t) = \\dfrac{d\\vec{\\chi}_p}{dt}$?\n",
      "\n",
      "   - When $t = 0$.  \n",
      "   - $\\vec{x} = 0$.  \n",
      "   - $\\vec{u} = 0$.  \n",
      "   - $\\vec{u} = \\vec{x}$.  \n",
      "   - $\\vec{x} = \\vec{\\chi}_P$.  \n",
      "   - $\\vec{u} = \\vec{\\chi}_P$.  \n",
      "   - $t = t_P$.  \n",
      "\n",
      "3. (c) For a Eulerian velocity field $\\vec{u}(\\vec{x}, t)$, which of the following would be sufficient to evaluate a particular value of the field?\n",
      "\n",
      "   - Pressure, $p$, temperature, $T$, and density, $\\rho$.  \n",
      "   - A Eulerian frame of reference.  \n",
      "   - A region of space, $\\vec{x}$, and a collection of particles $t$.  \n",
      "   - The continuum hypothesis.  \n",
      "   - A specific particle, $\\vec{\\chi}$, at a specific time, $t$.  \n",
      "   - A specific particle, $\\vec{\\chi}$, and a point in space $\\vec{x}$.  \n",
      "\n",
      "---\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extract title\n",
    "title = imported_tutorial[\"name\"]\n",
    "\n",
    "# Print the title\n",
    "print(f\"Title: {title}\\n\")\n",
    "\n",
    "# Extract questions\n",
    "questions = imported_tutorial[\"questions\"]\n",
    "\n",
    "# Loop over and print each question\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    print(f\"**Question {idx}**:\\n{question}\\n\")\n",
    "    print(\"-\" * 40)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving metadata to set_mech50010_fluid_mechanics_2_problem_set_1.json...\n"
     ]
    }
   ],
   "source": [
    "def create_tutorial_metadata(tutorial_title: str) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a metadata JSON object for a tutorial.\n",
    "\n",
    "    The metadata includes a normalized short name (generated by lowercasing the\n",
    "    title, replacing spaces with underscores, and removing unsafe characters),\n",
    "    as well as several fixed visibility settings and a release date.\n",
    "\n",
    "    Args:\n",
    "        tutorial_title (str): The full tutorial title.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the metadata.\n",
    "    \"\"\"\n",
    "    # Generate a short name for the tutorial (could name fancier using LLM).\n",
    "    # - convert to lower-case,\n",
    "    # - replace spaces with underscores,\n",
    "    # - remove any characters except letters, numbers, underscores, and hyphens.\n",
    "    normalized_name = tutorial_title.lower()                     # lower-case\n",
    "    normalized_name = re.sub(r'\\s+', '_', normalized_name)         # replace spaces with underscores\n",
    "    normalized_name = re.sub(r'[^a-z0-9_-]', '', normalized_name)   # remove other characters\n",
    "\n",
    "    # Build the metadata dictionary\n",
    "    metadata = {\n",
    "        \"name\": normalized_name,\n",
    "        \"description\": \"\",  # Optional description of the tutorial\n",
    "        \"releasedAt\": \"2024-09-30T11:00:00.000Z\",  # ISO 8601 release date\n",
    "        \"manuallyHidden\": True,  # Defaults to true\n",
    "        \"finalAnswerVisibility\": \"OPEN_WITH_WARNINGS\",\n",
    "        \"workedSolutionVisibility\": \"OPEN_WITH_WARNINGS\",\n",
    "        \"structuredTutorialVisibility\": \"OPEN\",\n",
    "        \"chatbotVisibility\": \"HIDE\"\n",
    "    }\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "metadata = create_tutorial_metadata(imported_tutorial[\"name\"])\n",
    "\n",
    "filename = f\"set_{metadata[\"name\"]}.json\"\n",
    "\n",
    "print(f\"Saving metadata to {filename}...\")\n",
    "json.dump(metadata, open(filename, \"w\"), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the nested Pydantic models based on the JSON schema.\n",
    "class WorkedSolution(BaseModel):\n",
    "    content: str = Field(..., description=\"Worked solution content\")\n",
    "    id: str = Field(..., description=\"Identifier for the worked solution\")\n",
    "    title: str = Field(..., description=\"Worked solution title\")\n",
    "\n",
    "class Part(BaseModel):\n",
    "    answer: str = Field(..., description=\"Part answer text\")\n",
    "    content: str = Field(..., description=\"Part content text\")\n",
    "    orderNumber: int = Field(..., description=\"The order number of this part\")\n",
    "    responseAreas: list = Field(..., description=\"List of response areas\")\n",
    "    tutorial: list = Field(..., description=\"List of tutorial items\")\n",
    "    universalPartId: str = Field(..., description=\"Universal part identifier\")\n",
    "    workedSolution: WorkedSolution = Field(..., description=\"Worked solution details\")\n",
    "\n",
    "class QuestionJson(BaseModel):\n",
    "    displayFinalAnswer: bool = Field(..., description=\"Flag to display the final answer\")\n",
    "    displayStructuredTutorial: bool = Field(..., description=\"Flag to display the structured tutorial\")\n",
    "    displayWorkedSolution: bool = Field(..., description=\"Flag to display the worked solution\")\n",
    "    masterContent: str = Field(..., description=\"Top level question content\")\n",
    "    parts: list[Part] = Field(..., description=\"List of question parts\")\n",
    "    publish: bool = Field(..., description=\"Publish flag\")\n",
    "    title: str = Field(..., description=\"Question title\")\n",
    "\n",
    "def create_question_json(question: str) -> dict:\n",
    "    # Initialize the output parser using the defined Pydantic model.\n",
    "    parser = PydanticOutputParser(pydantic_object=QuestionJson)\n",
    "\n",
    "    # Minimum JSON template to guide the model. (Used as context.)\n",
    "    minimum_json_template = r'''{\n",
    "      \"displayFinalAnswer\": true,\n",
    "      \"displayStructuredTutorial\": true,\n",
    "      \"displayWorkedSolution\": true,\n",
    "      \"masterContent\": \"Top level question here\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"answer\": \"\",\n",
    "          \"content\": \"Part text here\",\n",
    "          \"orderNumber\": 0,\n",
    "          \"responseAreas\": [],\n",
    "          \"tutorial\": [],\n",
    "          \"universalPartId\": \"N/A\",\n",
    "          \"workedSolution\": {\n",
    "            \"content\": \"Part worked solution here\",\n",
    "            \"id\": \"N/A\",\n",
    "            \"title\": \"\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"publish\": false,\n",
    "      \"title\": \"Question title here\"\n",
    "    }'''\n",
    "\n",
    "    # Construct the prompt, appending the parser's format instructions.\n",
    "    question_prompt = f'''\n",
    "      JSON_TEMPLATE\n",
    "      ```json\n",
    "      {minimum_json_template}\n",
    "      ```\n",
    "\n",
    "      IMPORTED_QUESTION\n",
    "      ```markdown\n",
    "      {question}\n",
    "      ```\n",
    "\n",
    "      If you see something like \"HII 5\\u201310 mins\\n\\n\", drop it from the text.\n",
    "\n",
    "      Carefully map IMPORTED_QUESTION into the JSON_TEMPLATE and return valid JSON.\n",
    "\n",
    "      {parser.get_format_instructions()}\n",
    "      '''\n",
    "\n",
    "    # Invoke the language model.\n",
    "    response = llm.invoke(question_prompt)\n",
    "\n",
    "    try:\n",
    "        # Parse the response using the output parser.\n",
    "        parsed_output = parser.parse(response.content)\n",
    "        return parsed_output.model_dump()  # Return as a dictionary.\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON from LLM response:\", e)\n",
    "        print(\"LLM response:\", response.content)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Define a Pydantic model representing the expected output schema.\n",
    "class QuestionName(BaseModel):\n",
    "    question_name: str = Field(..., description=\"A short tag representing the question’s topic.\")\n",
    "\n",
    "def create_question_name(question: str) -> str:\n",
    "    # Initialize the output parser with the schema.\n",
    "    parser = PydanticOutputParser(pydantic_object=QuestionName)\n",
    "\n",
    "    # Build a prompt that includes the parser's format instructions.\n",
    "    question_name_prompt = f'''\n",
    "      IMPORTED_QUESTION\n",
    "      ```markdown\n",
    "      {question}\n",
    "      ```\n",
    "      \n",
    "      QUERY:\n",
    "      Based on the above markdown content, infer a suitable short name tag that represents the question’s topic.\n",
    "      Follow these rules:\n",
    "      \n",
    "        1. Look for the heading text (for example, if the text starts with \"Question 1:\" followed by \"Hydraulic scale\", then the main topic is \"Hydraulic scale\").\n",
    "        2. Normalize the name by replacing spaces with underscores and removing punctuation.\n",
    "        3. Return only a valid JSON object with a single property \"question_name\".\n",
    "      \n",
    "      {parser.get_format_instructions()}\n",
    "    '''\n",
    "    # Invoke the language model.\n",
    "    response = llm.invoke(question_name_prompt)\n",
    "\n",
    "    try:\n",
    "        # Parse the response using the output parser.\n",
    "        parsed_output = parser.parse(response.content)\n",
    "        return parsed_output.question_name\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON from LLM response:\", e)\n",
    "        print(\"LLM response:\", response.content)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Mapping question in markdown into JSON\n",
      "INFO: Get question name.\n",
      "INFO: writing question_Hydraulic_scale.json\n"
     ]
    }
   ],
   "source": [
    "# Loop over and print each question\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    print(\"INFO: Mapping question in markdown into JSON\")\n",
    "    question_json = create_question_json(question)\n",
    "    \n",
    "    print(\"INFO: Get question name.\")\n",
    "    question_name = create_question_name(question)\n",
    "    \n",
    "    filename = f\"question_{question_name}.json\"\n",
    "    print(f\"INFO: writing {filename}\")\n",
    "    open(filename, \"w\").write(json.dumps(question_json, indent=2))\n",
    "    \n",
    "    break # breaking here as just doing quick test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
